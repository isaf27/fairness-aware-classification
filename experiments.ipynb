{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a402572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from algo import AdaFair, AdaBoost, SMOTEBoost, SMOTEBoostProtected, AdaFairCorrect\n",
    "\n",
    "from utils import get_dataset\n",
    "from metrics import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a323509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990718a2ee9d4f71b526d344bea01acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset adult\n",
      "Train size: (32561, 108), Test size: (16281, 108)\n",
      "Positive ratio (train): 0.241, Positive ratio (test): 0.236\n",
      "Protected ratio (train): 0.331, Protected ratio (test): 0.333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset bank\n",
      "Train size: (33908, 51), Test size: (11303, 51)\n",
      "Positive ratio (train): 0.117, Positive ratio (test): 0.117\n",
      "Protected ratio (train): 0.602, Protected ratio (test): 0.602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f07c830ec1484580cacf9662a3395a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_list = [\n",
    "    'adult',\n",
    "    'bank',\n",
    "    'compass',\n",
    "#     'kdd',\n",
    "]\n",
    "algorithms = [\n",
    "    AdaBoost,\n",
    "    AdaFair,\n",
    "    AdaFairCorrect,\n",
    "    SMOTEBoost,\n",
    "#     SMOTEBoostProtected,\n",
    "]\n",
    "train_metrics, test_metrics = {}, {}\n",
    "\n",
    "for dataset in tqdm(dataset_list):\n",
    "    print(f'Dataset {dataset}')\n",
    "    \n",
    "    X_train, y_train, is_protected_train, X_test, y_test, is_protected_test = get_dataset(dataset)\n",
    "    \n",
    "    print(f'Train size: {X_train.shape}, Test size: {X_test.shape}')\n",
    "    print(f'Positive ratio (train): {y_train.mean():.3f}, Positive ratio (test): {y_test.mean():.3f}')\n",
    "    print(f'Protected ratio (train): {is_protected_train.mean():.3f}, Protected ratio (test): {is_protected_test.mean():.3f}')\n",
    "    \n",
    "    for model_class in tqdm(algorithms, position=1, leave=False):\n",
    "        model = model_class()\n",
    "        model.fit(X_train, y_train, is_protected_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        train_metrics[dataset, model_class.__name__] = calculate_metrics(y_train, y_train_pred, is_protected_train)\n",
    "        test_metrics[dataset, model_class.__name__] = calculate_metrics(y_test, y_test_pred, is_protected_test)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb00ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(ax, metrics, dataset):\n",
    "    metric_names = metrics[dataset, algorithms[0].__name__].keys()\n",
    "    x = np.arange(len(metric_names))\n",
    "    width = 0.25  # the width of the bars\n",
    "    ax.yaxis.grid()\n",
    "    for i, algo in enumerate(algorithms):\n",
    "        algo_name = algo.__name__\n",
    "        measurement = [metrics[dataset, algo_name][m] for m in metric_names]\n",
    "        rects = ax.bar(x + width * i, measurement, width, label=algo_name)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_xticks(x + width * (len(algorithms) - 1) / 2, metric_names, rotation=30,\n",
    "                  rotation_mode=\"anchor\", horizontalalignment='right', verticalalignment='top')\n",
    "\n",
    "for metrics, name in [(test_metrics, 'test'), (train_metrics, 'train')]:\n",
    "    _, axes = plt.subplots(1, len(dataset_list), figsize=(15, 3))\n",
    "    if len(dataset_list) == 1:\n",
    "        axes = [axes]\n",
    "    print(name, 'metrics:')\n",
    "    for dataset, ax in zip(dataset_list, axes):\n",
    "        plot_metrics(ax, train_metrics, dataset)\n",
    "        ax.set_title(dataset)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845a1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
